ตัวใช้ทดสอบ n8n ต่อ Ollama server ด้วย local ip ของ lan wifi เดียวกัน   เป็น file GGUF  
เทสด้วย virtual box bridge network
ใช้โมเดล bagnacan/llama3_instruct  
https://ollama.com/bagnacan/llama3_instruct   
โมเดลนี้ใช้ram 8      
cpu ทดสอบ : Intel i5-8250U (8) @ 3.400GHz


run docker compose ใน โฟลเดอร์ server กับ client ครับ
